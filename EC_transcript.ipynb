{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EC_transcript.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfEjcZiUD4LHPW3K9RWZG/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyyoung3/python_stock_analysis/blob/main/EC_transcript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkQ895RZzji2",
        "outputId": "03a60eb2-3738-4d2d-a079-f2aa41c03c6f"
      },
      "source": [
        "!pip install bs4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gRKgmi7z70P"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "import time\n",
        "import re"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLm9b5O91mXJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4UKMSwan2rY"
      },
      "source": [
        "q = ['q1','q2','q3','q4']\n",
        "p1 = re.compile(r'[(](.*?:.*?)[)]',re.S)\n",
        "p2 = re.compile(r'[)](Q.*?)E',re.S)\n"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHeqXr8O3Wbh"
      },
      "source": [
        "def parsing (url):\n",
        "  if 1==1:      \n",
        "    response = requests.get(url)\n",
        "\n",
        "    soup = BeautifulSoup(response.text,\"html.parser\")\n",
        "    texts = soup.find_all('span','article-content')\n",
        "\n",
        "    #parse transcript\n",
        "    for text in texts :\n",
        "      line = 1\n",
        "      year = ''\n",
        "      qu = ''\n",
        "      stock = ''\n",
        "      \n",
        "      for p in text.find_all('p'): #loop each line in transcript\n",
        "          # print(p)\n",
        "          if line == 1:\n",
        "            pass\n",
        "          if line == 2:\n",
        "            # print(p.get_text())\n",
        "            year = re.findall(p2,p.get_text())[0].split()[1]\n",
        "            # print(year)\n",
        "            qu = re.findall(p2,p.get_text())[0].split()[0]\n",
        "            # print(qu)\n",
        "            stock = re.findall(p1,p.get_text())[0].split(':')[1]\n",
        "            # print(stock)\n",
        "\n",
        "            try: #check if stock folder exists\n",
        "              os.makedirs(stock.upper())\n",
        "            except FileExistsError:\n",
        "              pass\n",
        "            #file name is stock quote + quarter + year\n",
        "            file = stock.upper()+'/'+qu+str(year) +'.txt'\n",
        "            myfile = open(file,'w')\n",
        "            myfile.write(p.get_text()) #overwrite if file already exists\n",
        "            myfile.close()           \n",
        "          # print(url)\n",
        "          else :\n",
        "            file = stock.upper()+'/'+ qu+str(year) +'.txt'\n",
        "            myfile = open(file,'a')\n",
        "            if 'Analyst' in p.get_text():\n",
        "              myfile.write(p.get_text() + ' ')\n",
        "            else:\n",
        "              myfile.write(p.get_text())\n",
        "          line += 1\n",
        "      myfile.close()\n",
        "    print('Saved ' +stock + '-'+qu+str(year) + '.txt' + ' to folder '+stock.upper() )\n",
        "\n",
        "\n"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XyU0bXGAz5K"
      },
      "source": [
        "def file_gen(page,log_file):\n",
        "  url = 'https://www.fool.com/author/20032/?page=' + str(page) \n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text,\"html.parser\")\n",
        "  err = open('logs/' + str(log_file) + '.txt','a')\n",
        "  err.write('start'+'\\n')\n",
        "\n",
        "  links = soup.find('div','list-content')\n",
        "  for a in links.find_all('a'):\n",
        "    # print(a['href'])\n",
        "    url = 'https://www.fool.com'+ a['href']\n",
        "    try:\n",
        "      parsing(url)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      err.write(a['href'] + ' - ' + str(e))\n",
        "\n",
        "    time.sleep(5)\n",
        "  err.write('End processing. ' + str(i) + ' page(s) is loaded')\n",
        "  err.close()\n"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6e8gwAf0q1A",
        "outputId": "51cd3f6e-1ec9-4bb9-a588-b850b7bae52c"
      },
      "source": [
        "from datetime import datetime\n",
        "try: #check if log folder exists\n",
        "  os.makedirs('logs')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "log_file = datetime.now()\n",
        "log = open('logs/' + str(log_file) + '.txt','w') #create log\n",
        "log.close()\n",
        "\n",
        "for i in range(1,2): #pages you want to download\n",
        "  file_gen(i,log_file)\n"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved LOVE-Q22022.txt to folder LOVE\n",
            "Saved JG-Q22021.txt to folder JG\n",
            "Saved ASO-Q22021.txt to folder ASO\n",
            "Saved VIAO-Q22021.txt to folder VIAO\n",
            "Saved ZS-Q42021.txt to folder ZS\n",
            "Saved VRNT-Q22022.txt to folder VRNT\n",
            "Saved ZUMZ-Q22021.txt to folder ZUMZ\n",
            "Saved AFRM-Q42021.txt to folder AFRM\n",
            "Saved LAKE-Q22022.txt to folder LAKE\n",
            "Saved CXM-Q22022.txt to folder CXM\n",
            "Saved SUMO-Q22022.txt to folder SUMO\n",
            "Saved KR-Q22021.txt to folder KR\n",
            "Saved TIGR-Q22021.txt to folder TIGR\n",
            "Saved ORCL-Q12022.txt to folder ORCL\n",
            "Saved AVO-Q32021.txt to folder AVO\n",
            "Saved MYTE-Q42021.txt to folder MYTE\n",
            "Saved FCEL-Q32021.txt to folder FCEL\n",
            "Saved ASPU-Q12022.txt to folder ASPU\n",
            "Saved IBEX-Q42021.txt to folder IBEX\n",
            "Saved JKS-Q22021.txt to folder JKS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LaGi7q2V5BSd",
        "outputId": "451143b5-a1fd-4873-8e32-f03beaf95d25"
      },
      "source": [
        "p1 = re.compile(r'[(](.*?:.*?)[)]',re.S)\n",
        "\n",
        "\n",
        "test1 = 'The Lovesac Company (NASDAQ:LOVE)Q2 2022 Earnings CallSep 09, 2021, 8:30 a.m. ET'\n",
        "test = 'John Wiley & Sons (A Shares) (NYSE:JW.A)Q1 2022 Earnings CallSep 02, 2021, 10:00 a.m. ET'\n",
        "\n",
        "\n",
        "re.findall(p1,test)[0].split(\":\")[1]\n",
        "\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'JW.A'"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    }
  ]
}